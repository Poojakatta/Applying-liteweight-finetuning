{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LoRA - Chosen for its efficiency in reducing trainable parameters while maintaining high performance.\n",
    "* Model:  GPT-2 - Selected for its versatility, strong pre-trained knowledge, and small size that doesn't require much memory.\n",
    "* Evaluation approach: F1 Score and Accuracy - Used for their ability to provide a balanced evaluation and a clear measure of overall performance.\n",
    "* Fine-tuning dataset: SMS-SPAM - Picked for its relevance to the specific task, high-quality data, small size, and simplicity in evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/student/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92585d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# Add a padding token to the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=2,\n",
    "    id2label={0: \"not_spam\", 1: \"spam\"}, \n",
    "    label2id={\"not_spam\": 0, \"spam\": 1})\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sms', 'label'],\n",
      "        num_rows: 4459\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sms', 'label'],\n",
      "        num_rows: 1115\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"sms_spam\")\n",
    "\n",
    "if 'test' not in dataset:\n",
    "    dataset = dataset['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c892540867b54e5ea58de80f56baac19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f288bb5f79f44d0bb8b167d5fc5b2cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['sms'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Ensure tensors are on CPU before converting to numpy\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1674' max='1674' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1674/1674 07:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.228545</td>\n",
       "      <td>0.908537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.048986</td>\n",
       "      <td>0.979866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.052819</td>\n",
       "      <td>0.973154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05281892046332359, 'eval_f1': 0.9731543624161074, 'eval_runtime': 9.0145, 'eval_samples_per_second': 123.689, 'eval_steps_per_second': 15.53, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    \n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the FOUNDATION model\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in /home/student/.local/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.36.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /home/student/.local/lib/python3.10/site-packages (from peft) (4.66.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/student/.local/lib/python3.10/site-packages (from peft) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.0)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/student/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/student/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/student/.local/lib/python3.10/site-packages (from accelerate->peft) (0.21.4)\n",
      "Requirement already satisfied: requests in /home/student/.local/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate->peft) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/student/.local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers->peft) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers->peft) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers->peft) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers->peft) (3.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEFT Technique: I chose LoRA for its efficiency and minimal parameter usage.\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(r=4, #ranking\n",
    "                   lora_alpha=32,\n",
    "                   target_modules=[\"c_attn\", \"c_proj\"],\n",
    "                   lora_dropout=0.2,\n",
    "                   bias=\"none\",\n",
    "                   task_type=\"CAUSAL_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lora_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d7ef49a2f495595ddefee48727272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba6676dfcd24b38902830ae3a571033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e87b57d7b174354a22b6483d541e454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65a935a389c40eab2cdd3701f7e7c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb27b00610b4799a4f6c89298fe2bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2151594415f946eb93d200bd5dab86c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('sms_spam')\n",
    "\n",
    "if 'test' not in dataset:\n",
    "    dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Ensure the dataset has the correct format for training\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "# Add labels for language modeling\n",
    "tokenized_datasets = tokenized_datasets.map(lambda examples: {'labels': examples['input_ids']}, batched=True)\n",
    "\n",
    "# Filter out any examples that might be None or empty\n",
    "tokenized_datasets = tokenized_datasets.filter(lambda example: example['input_ids'] is not None and len(example['input_ids']) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa5f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "torch.cuda.empty_cache()\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1, \n",
    "    per_device_eval_batch_size=1, \n",
    "    gradient_accumulation_steps=4,\n",
    "    fp16=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660525d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1100' max='2228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1100/2228 06:07 < 06:17, 2.99 it/s, Epoch 0.99/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-10 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-30 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-40 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-50 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-60 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-70 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-80 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-90 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-100 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-110 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-120 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-130 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-140 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-150 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-160 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-170 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-180 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-190 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-200 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-210 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-220 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-230 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-240 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-260 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-270 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-280 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-290 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-300 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-310 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-320 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-330 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-340 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-350 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-360 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-370 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-380 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-390 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-400 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-410 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-420 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-430 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-440 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-450 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-460 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-470 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-480 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-490 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-510 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-520 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-530 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-540 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-550 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-560 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-570 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-580 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-590 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-600 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-610 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-620 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-630 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-640 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-650 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-660 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-670 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-680 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-690 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-700 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-710 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-720 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-730 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-740 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-750 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-760 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-770 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-780 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-790 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-800 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-810 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-820 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-830 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-840 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-850 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-860 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-870 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-880 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-890 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-900 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-910 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-920 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-930 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-940 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-950 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-960 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-970 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-980 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-990 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1010 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1020 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1030 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1040 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1050 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1060 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1070 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1080 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1090 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "def data_collator(features):\n",
    "    batch = {}\n",
    "    for k, v in features[0].items():\n",
    "        batch[k] = torch.stack([f[k] for f in features])\n",
    "    return batch\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064462f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d73395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the PEFT-tuned classification model\n",
    "lora_model = AutoModelForSequenceClassification.from_pretrained(\"gpt-lora\", num_labels=2,\n",
    "    id2label={0: \"not_spam\", 1: \"spam\"}, \n",
    "    label2id={\"not_spam\": 0, \"spam\": 1})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my name is call me immediateyly\", return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = lora_model(**inputs)\n",
    "    logits = outputs.logits    \n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "label = lora_model.config.id2label[predicted_class]\n",
    "print(f\"Predicted label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
